# ğŸ“— PHáº¦N Há»ŒC Cá»¦A LÃŠ ÄÄ‚NG KHOA
## Game Logic & AI System

---

## ğŸ¯ Vai TrÃ² Cá»§a Báº¡n

Báº¡n chá»‹u trÃ¡ch nhiá»‡m **bá»™ nÃ£o cá»§a game** - pháº§n logic kiá»ƒm tra tháº¯ng thua vÃ  há»‡ thá»‘ng AI thÃ´ng minh. ÄÃ¢y lÃ  pháº§n quan trá»ng nháº¥t quyáº¿t Ä‘á»‹nh áº£i cÃ³ há»£p lá»‡, ai tháº¯ng ai thua, vÃ  lÃ m sao AI cÃ³ thá»ƒ chÆ¡i game má»™t cÃ¡ch thÃ´ng minh. Báº¡n sáº½ lÃ m viá»‡c vá»›i thuáº­t toÃ¡n ná»•i tiáº¿ng **Minimax** vÃ  ká»¹ thuáº­t tá»‘i Æ°u **Alpha-Beta Pruning**.

---

## ğŸ“š Kiáº¿n Thá»©c Cáº§n Náº¯m

### 1. Thuáº­t ToÃ¡n Minimax - Ná»n Táº£ng AI Game

Minimax lÃ  thuáº­t toÃ¡n tÃ¬m nÆ°á»›c Ä‘i tá»‘i Æ°u báº±ng cÃ¡ch **giáº£ Ä‘á»‹nh Ä‘á»‘i thá»§ cÅ©ng chÆ¡i tá»‘i Æ°u**.

#### **Ã TÆ°á»Ÿng Cá»‘t LÃµi**

TÆ°á»Ÿng tÆ°á»£ng báº¡n chÆ¡i cá» caro:
1. Báº¡n cÃ³ thá»ƒ Ä‘i 10 nÆ°á»›c khÃ¡c nhau
2. Vá»›i má»—i nÆ°á»›c Ä‘i cá»§a báº¡n, Ä‘á»‘i thá»§ láº¡i cÃ³ 9 nÆ°á»›c Ä‘i
3. Rá»“i báº¡n láº¡i cÃ³ 8 nÆ°á»›c Ä‘i tiáº¿p theo...

Minimax sáº½ **duyá»‡t háº¿t** táº¥t cáº£ cÃ¡c kháº£ nÄƒng nÃ y vÃ  chá»n nÆ°á»›c Ä‘i tá»‘t nháº¥t.

#### **CÃ¡ch Hoáº¡t Äá»™ng**

```
       LÆ°á»£t Max (AI)
      /      |      \
    -1       5       3     â† Äiá»ƒm cá»§a má»—i nÆ°á»›c Ä‘i
   / \      / \     / \
  -1  0    2  5    3  -2   LÆ°á»£t Min (Human)
```

- **Max Layer** (AI): Chá»n nÆ°á»›c Ä‘i cÃ³ Ä‘iá»ƒm **cao nháº¥t**
- **Min Layer** (Human): Chá»n nÆ°á»›c Ä‘i cÃ³ Ä‘iá»ƒm **tháº¥p nháº¥t** (vÃ¬ muá»‘n AI thua)

**VÃ­ dá»¥ cá»¥ thá»ƒ vá»›i Tic-Tac-Toe**:

```python
def minimax(board, depth, is_maximizing):
    # Náº¿u game káº¿t thÃºc, tráº£ vá» Ä‘iá»ƒm
    winner = check_winner(board)
    if winner == AI: return 100
    if winner == HUMAN: return -100
    if is_draw(board): return 0
    
    if is_maximizing:  # LÆ°á»£t AI
        best_score = -infinity
        for move in get_possible_moves(board):
            board[move] = AI
            score = minimax(board, depth+1, False)
            board[move] = EMPTY  # Undo move
            best_score = max(best_score, score)
        return best_score
    
    else:  # LÆ°á»£t Human
        best_score = +infinity
        for move in get_possible_moves(board):
            board[move] = HUMAN
            score = minimax(board, depth+1, True)
            board[move] = EMPTY
            best_score = min(best_score, score)
        return best_score
```

**Giáº£i thÃ­ch**:
- AI muá»‘n **maximize** Ä‘iá»ƒm â†’ chá»n `max()`
- Human muá»‘n **minimize** Ä‘iá»ƒm cá»§a AI â†’ chá»n `min()`
- Äá»‡ quy cho Ä‘áº¿n khi game káº¿t thÃºc hoáº·c Ä‘áº¡t depth limit

**Äá»™ phá»©c táº¡p**: O(b^d) vá»›i b = sá»‘ nÆ°á»›c Ä‘i má»—i lÆ°á»£t, d = Ä‘á»™ sÃ¢u
- Tic-Tac-Toe: 9^9 = 387,420,489 nodes (cÃ³ thá»ƒ duyá»‡t háº¿t)
- Caro: 300^20 = khÃ´ng tÆ°á»Ÿng â†’ cáº§n Alpha-Beta Pruning + heuristic

### 2. Alpha-Beta Pruning - Tá»‘i Æ¯u Minimax

Ká»¹ thuáº­t cáº¯t tá»‰a cÃ¡c nhÃ¡nh khÃ´ng cáº§n thiáº¿t.

#### **Ã TÆ°á»Ÿng**

```
         Max
        /   \
      3      ?
     / \
    3   5
```

Giáº£ sá»­ Ä‘ang á»Ÿ Max layer, Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c nÆ°á»›c Ä‘i cho Ä‘iá»ƒm 3.

BÃ¢y giá» xÃ©t nhÃ¡nh pháº£i `?`:
- VÃ o Min layer bÃªn trong
- Min tÃ¬m Ä‘Æ°á»£c Ä‘iá»ƒm 2
- â†’ Min sáº½ chá»n <=2 (vÃ¬ Min muá»‘n Ä‘iá»ƒm tháº¥p)
- â†’ Max khÃ´ng bao giá» chá»n nhÃ¡nh `?` nÃ y (vÃ¬ Ä‘Ã£ cÃ³ nhÃ¡nh 3 tá»‘t hÆ¡n)
- â†’ **Cáº¯t bá»** nhÃ¡nh `?`, khÃ´ng cáº§n duyá»‡t ná»¯a

#### **CÃ¡ch Implement**

```python
def minimax(board, depth, alpha, beta, is_maximizing):
    if game_over: return evaluate(board)
    
    if is_maximizing:
        max_score = -infinity
        for move in moves:
            score = minimax(board, depth+1, alpha, beta, False)
            max_score = max(max_score, score)
            alpha = max(alpha, score)
            if beta <= alpha:  # Pruning!
                break
        return max_score
    else:
        min_score = +infinity
        for move in moves:
            score = minimax(board, depth+1, alpha, beta, True)
            min_score = min(min_score, score)
            beta = min(beta, score)
            if beta <= alpha:  # Pruning!
                break
        return min_score
```

**Hiá»‡u quáº£**: Giáº£m tá»« O(b^d) xuá»‘ng O(b^(d/2)) trong trÆ°á»ng há»£p tá»‘t nháº¥t!

### 3. Heuristic Evaluation - ÄÃ¡nh GiÃ¡ Vá»‹ TrÃ­

VÃ¬ khÃ´ng thá»ƒ duyá»‡t háº¿t cÃ¢y game vá»›i Caro, cáº§n hÃ m Ä‘Ã¡nh giÃ¡ vá»‹ trÃ­:

```python
def evaluate_board(board):
    score = 0
    
    # QuÃ©t táº¥t cáº£ cÃ¡c hÃ ng/cá»™t/chÃ©o
    for line in all_lines(board):
        ai_count = count_ai_pieces(line)
        human_count = count_human_pieces(line)
        
        # Náº¿u line cÃ³ cáº£ AI vÃ  Human â†’ khÃ´ng tÃ­nh (bá»‹ block)
        if ai_count > 0 and human_count > 0:
            continue
        
        # TÃ­nh Ä‘iá»ƒm cho AI
        if ai_count == 4: score += 100000  # Sáº¯p tháº¯ng
        elif ai_count == 3: score += 1000
        elif ai_count == 2: score += 10
        
        # Trá»« Ä‘iá»ƒm náº¿u Human cÃ³ line
        if human_count == 4: score -= 100000
        elif human_count == 3: score -= 1000
        elif human_count == 2: score -= 10
    
    return score
```

**Trong project Caro**, cÃ³ cÃ¡c patterns Ä‘áº·c biá»‡t:
- **Open 4** (4 Ã´ liÃªn tiáº¿p, 2 Ä‘áº§u trá»‘ng): 100,000 Ä‘iá»ƒm
- **Blocked 4**: 1,000 Ä‘iá»ƒm
- **Open 3**: 500 Ä‘iá»ƒm
- ...

### 4. Game State Representation

BÃ n cá» Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng máº£ng 2D:

```python
# Tic-Tac-Toe (3x3)
board = [
    [0, 1, 0],
    [2, 1, 0],
    [0, 0, 2]
]

# Caro (15x20)
board = [[0] * 20 for _ in range(15)]
```

**Quy Æ°á»›c**:
- `0`: Ã” trá»‘ng
- `1`: Player 1 (X)
- `2`: Player 2 (O)

---

## ğŸ“‚ Files Báº¡n Phá»¥ TrÃ¡ch

### 1. `backend/game/engine.py` (149 dÃ²ng) - Game Engine

**Vai trÃ²**: Core logic cá»§a game - táº¡o bÃ n cá», kiá»ƒm tra valid move, check winner

**CÃ¡c hÃ m chÃ­nh**:

#### `create_board(game_type)`
Táº¡o bÃ n cá» trá»‘ng theo loáº¡i game:
```python
def create_board(game_type):
    config = GAME_CONFIG.get(game_type)
    rows = config['rows']  # 3 (ttt) hoáº·c 15 (caro)
    cols = config['cols']  # 3 (ttt) hoáº·c 20 (caro)
    return [[0 for _ in range(cols)] for _ in range(rows)]
```

#### `is_valid_move(board, r, c)`
Kiá»ƒm tra nÆ°á»›c Ä‘i cÃ³ há»£p lá»‡ khÃ´ng:
```python
def is_valid_move(board, r, c):
    rows = len(board)
    cols = len(board[0])
    
    # NgoÃ i biÃªn?
    if not (0 <= r < rows and 0 <= c < cols):
        return False
    
    # Ã” Ä‘Ã£ cÃ³ quÃ¢n?
    return board[r][c] == 0
```

#### `apply_move(board, r, c, player)`
Äáº·t quÃ¢n lÃªn bÃ n cá»:
```python
def apply_move(board, r, c, player):
    if not is_valid_move(board, r, c):
        return False
    board[r][c] = player
    return True
```

#### `check_winner(board, game_type, last_move)` - QUAN TRá»ŒNG NHáº¤T!

Kiá»ƒm tra tháº¯ng/thua sau nÆ°á»›c Ä‘i cuá»‘i:

```python
def check_winner(board, game_type, last_move):
    if not last_move:
        return 0, None
    
    r, c = last_move['r'], last_move['c']
    player = board[r][c]
    win_len = GAME_CONFIG[game_type]['win_length']  # 3 hoáº·c 5
    
    # Kiá»ƒm tra 4 hÆ°á»›ng: ngang, dá»c, chÃ©o xuá»‘ng, chÃ©o lÃªn
    for dr, dc in [(0,1), (1,0), (1,1), (1,-1)]:
        line = [(r, c)]
        
        # Äáº¿m tiáº¿n
        for i in range(1, win_len):
            nr, nc = r + dr*i, c + dc*i
            if in_bounds(nr, nc) and board[nr][nc] == player:
                line.append((nr, nc))
            else:
                break
        
        # Äáº¿m lÃ¹i
        for i in range(1, win_len):
            nr, nc = r - dr*i, c - dc*i
            if in_bounds(nr, nc) and board[nr][nc] == player:
                line.append((nr, nc))
            else:
                break
        
        # Náº¿u Ä‘á»§ win_length â†’ tháº¯ng!
        if len(line) >= win_len:
            return player, line
    
    # Kiá»ƒm tra hÃ²a (board Ä‘áº§y)
    if all(board[row][col] != 0 for row in range(rows) for col in range(cols)):
        return 'draw', None
    
    return 0, None  # ChÆ°a káº¿t thÃºc
```

**Vá»‹ trÃ­**: `c:\xampp\htdocs\Caro\backend\game\engine.py`

### 2. `backend/game/ai.py` (683 dÃ²ng) - AI Logic

**Vai trÃ²**: Thuáº­t toÃ¡n AI cho cáº£ Tic-Tac-Toe vÃ  Caro

**Entry Point**:

```python
def get_ai_move(board, game_type, difficulty):
    if game_type == 'tic-tac-toe':
        return _get_tictactoe_move(board, difficulty)
    else:  # caro
        return _get_caro_move(board, difficulty)
```

**Cho Tic-Tac-Toe**:

#### `_get_tictactoe_move(board, difficulty)`
```python
def _get_tictactoe_move(board, difficulty):
    if difficulty == 'easy':
        # Ngáº«u nhiÃªn 100%
        moves = get_empty_cells(board)
        return random.choice(moves)
    
    elif difficulty == 'medium':
        # 30% ngáº«u nhiÃªn, 70% Minimax
        if random.random() < 0.3:
            return random.choice(get_empty_cells(board))
        # Fall through to Minimax
    
    # Hard hoáº·c Medium (70% case)
    return _full_minimax_ttt(board)
```

#### `_minimax_ttt(board, depth, is_maximizing, alpha, beta)`
```python
def _minimax_ttt(board, depth, is_maximizing, alpha, beta, cache):
    # Check cache Ä‘á»ƒ trÃ¡nh tÃ­nh láº¡i
    state = serialize(board)
    if state in cache:
        return cache[state]
    
    # Check káº¿t thÃºc
    winner = _check_winner_simple(board)
    if winner == 2: return 10 - depth  # AI tháº¯ng
    if winner == 1: return depth - 10  # Human tháº¯ng
    if winner == 'draw': return 0
    
    if is_maximizing:  # AI
        max_score = -infinity
        for r, c in get_empty_cells(board):
            board[r][c] = 2
            score = _minimax_ttt(board, depth+1, False, alpha, beta, cache)
            board[r][c] = 0
            max_score = max(max_score, score)
            alpha = max(alpha, score)
            if beta <= alpha: break  # Pruning
        cache[state] = max_score
        return max_score
    else:  # Human
        min_score = infinity
        for r, c in get_empty_cells(board):
            board[r][c] = 1
            score = _minimax_ttt(board, depth+1, True, alpha, beta, cache)
            board[r][c] = 0
            min_score = min(min_score, score)
            beta = min(beta, score)
            if beta <= alpha: break
        cache[state] = min_score
        return min_score
```

**Cho Caro**:

#### `_get_caro_move(board, difficulty)`
```python
def _get_caro_move(board, difficulty):
    moves = _get_neighbor_moves(board, radius=2)  # Chá»‰ xÃ©t Ã´ gáº§n quÃ¢n cá»
    
    if difficulty == 'easy':
        return random.choice(moves)
    
    # Medium: depth 1, Hard: depth 2
    depth = 1 if difficulty == 'medium' else 2
    
    # TÃ¬m nÆ°á»›c tháº¯ng ngay
    win_move = _find_immediate_caro_move(board, moves, player=2)
    if win_move: return win_move
    
    # Cháº·n Ä‘á»‘i thá»§ tháº¯ng ngay
    block_move = _find_immediate_caro_move(board, moves, player=1)
    if block_move: return block_move
    
    # TÃ¬m nÆ°á»›c táº¡o open-4 (tháº¯ng cháº¯c)
    vcf_move = _find_vcf_move(board, moves, player=2)
    if vcf_move: return vcf_move
    
    # Minimax vá»›i depth limit
    best_move = None
    best_score = -infinity
    
    # Sort moves theo urgency
    moves = _order_moves_by_urgency(board, moves, player=2, limit=15)
    
    for r, c in moves:
        board[r][c] = 2
        score = _minimax_caro(board, depth, False, -infinity, infinity, (r,c))
        board[r][c] = 0
        if score > best_score:
            best_score = score
            best_move = (r, c)
    
    return best_move
```

**Vá»‹ trÃ­**: `c:\xampp\htdocs\Caro\backend\game\ai.py`

### 3. `components/GameBoard.tsx` (216 dÃ²ng) - UI BÃ n Cá»

**Vai trÃ²**: Hiá»ƒn thá»‹ bÃ n cá» vÃ  xá»­ lÃ½ click cá»§a user

**CÃ¡c features**:
- Render 3x3 grid cho Tic-Tac-Toe
- Render 15x20 grid cho Caro
- Drag-to-pan cho Caro (kÃ©o bÃ n cá»)
- Highlight winning line
- Hiá»ƒn thá»‹ last move
- Undo button

**Vá»‹ trÃ­**: `c:\xampp\htdocs\Caro\components\GameBoard.tsx`

---

## ğŸ”„ Luá»“ng Hoáº¡t Äá»™ng Chi Tiáº¿t

### A. Luá»“ng Kiá»ƒm Tra Tháº¯ng/Thua

**BÆ°á»›c 1: Player Ä‘áº·t quÃ¢n**
- Frontend gá»­i socket event `make_move` vá»›i `(r, c, player)`
- Backend nháº­n trong `sockets/game.py`

**BÆ°á»›c 2: Validate vÃ  apply move**
```python
# In sockets/game.py
game = games[room_id]
board = game['board']

# Kiá»ƒm tra valid
if not GameEngine.is_valid_move(board, r, c):
    return  # Ignore invalid move

# Apply move
GameEngine.apply_move(board, r, c, player)
game['history'].append({'r': r, 'c': c, 'player': player})
```

**BÆ°á»›c 3: Check winner**
```python
winner, winning_line = GameEngine.check_winner(
    board, 
    game_type='caro', 
    last_move={'r': r, 'c': c}
)
```

**BÆ°á»›c 4: Xá»­ lÃ½ káº¿t quáº£**
```python
if winner != 0:  # CÃ³ ngÆ°á»i tháº¯ng hoáº·c hÃ²a
    _handle_end_game(game, winner)
    # â†’ Update rank points, save match history
else:
    # Chuyá»ƒn lÆ°á»£t
    game['turn'] = 3 - game['turn']  # 1â†’2, 2â†’1
```

**BÆ°á»›c 5: Emit vá» clients**
```python
socketio.emit('game_update', {
    'board': board,
    'currentPlayer': game['turn'],
    'winner': winner,
    'winningLine': winning_line,
    'lastMove': {'r': r, 'c': c}
}, room=room_id)
```

### B. Luá»“ng AI Move (Practice Mode)

**BÆ°á»›c 1: PhÃ¡t hiá»‡n lÆ°á»£t AI**
```python
# In sockets/game.py sau khi human move
if game['mode'] == 'practice' and game['turn'] == 2:
    _handle_ai_move(socketio, room_id, game)
```

**BÆ°á»›c 2: TÃ­nh nÆ°á»›c Ä‘i AI**
```python
def _handle_ai_move(socketio, room_id, game):
    board = game['board']
    difficulty = game['difficulty']
    game_type = game['type']
    
    # Delay tÃ¹y Ä‘á»™ khÃ³
    delay = {
        'easy': 0.3,
        'medium': 0.6,
        'hard': 1.0
    }[difficulty]
    
    time.sleep(delay)  # Giáº£ láº­p AI "suy nghÄ©"
    
    # Gá»i AI
    r, c = AIPlayer.get_ai_move(board, game_type, difficulty)
```

**BÆ°á»›c 3: Apply AI move**
```python
    GameEngine.apply_move(board, r, c, 2)
    game['history'].append({'r': r, 'c': c, 'player': 2})
    
    # Check winner
    winner, winning_line = GameEngine.check_winner(
        board, game_type, {'r': r, 'c': c}
    )
    
    # Emit update
    socketio.emit('game_update', {
        'board': board,
        'currentPlayer': 1,  # Chuyá»ƒn láº¡i lÆ°á»£t human
        'winner': winner,
        'winningLine': winning_line,
        'lastMove': {'r': r, 'c': c}
    }, room=room_id)
```

### C. Luá»“ng Minimax Chi Tiáº¿t (Tic-Tac-Toe)

**VÃ­ dá»¥ cá»¥ thá»ƒ**:

```
Board hiá»‡n táº¡i:
X | O | 
---------
  | X | 
---------
  |   | O

AI = X, Human = O, LÆ°á»£t AI
```

**BÆ°á»›c 1: Liá»‡t kÃª nÆ°á»›c Ä‘i**
Empty cells: (0,2), (1,0), (2,0), (2,1)

**BÆ°á»›c 2: Duyá»‡t tá»«ng nÆ°á»›c**
```python
for r, c in empty_cells:
    board[r][c] = 2  # Thá»­ Ä‘áº·t X
    score = minimax(board, depth+1, False, -inf, +inf)
    board[r][c] = 0  # Undo
    
    if score > best_score:
        best_score = score
        best_move = (r, c)
```

**BÆ°á»›c 3: Äá»‡ quy sÃ¢u hÆ¡n**
Giáº£ sá»­ thá»­ (0,2):
```
X | O | X  â† Thá»­ nÆ°á»›c nÃ y
---------
  | X | 
---------
  |   | O

â†’ Giá» lÆ°á»£t Human (Min layer)
â†’ Human thá»­ (1,0):
  X | O | X
  ---------
  O | X | 
  ---------
    |   | O
  
  â†’ Giá» láº¡i lÆ°á»£t AI (Max layer)
  â†’ AI thá»­ (2,0):
    X | O | X
    ---------
    O | X | 
    ---------
    X |   | O
    
    â†’ Check winner: X tháº¯ng (cá»™t Ä‘áº§u tiÃªn)
    â†’ Return +10
```

**BÆ°á»›c 4: Backpropagation**
- Tá»« lÃ¡ (X tháº¯ng, +10) bubble up vá» root
- Min layer sáº½ chá»n min cá»§a cÃ¡c nhÃ¡nh con
- Max layer sáº½ chá»n max cá»§a cÃ¡c nhÃ¡nh con

**BÆ°á»›c 5: Chá»n nÆ°á»›c Ä‘i tá»‘t nháº¥t**
```python
# Sau khi duyá»‡t háº¿t, best_move lÃ  nÆ°á»›c cÃ³ Ä‘iá»ƒm cao nháº¥t
return best_move
```

---

## ğŸ“‹ Báº£ng CÃ¡c HÃ m Quan Trá»ng

| HÃ m | File | Tham sá»‘ | Chá»©c nÄƒng |
|-----|------|---------|-----------|
| `create_board` | engine.py | game_type | Táº¡o bÃ n cá» trá»‘ng (3x3 hoáº·c 15x20) |
| `is_valid_move` | engine.py | board, r, c | Kiá»ƒm tra nÆ°á»›c Ä‘i cÃ³ há»£p lá»‡ khÃ´ng |
| `apply_move` | engine.py | board, r, c, player | Äáº·t quÃ¢n lÃªn bÃ n cá» |
| `check_winner` | engine.py | board, game_type, last_move | Kiá»ƒm tra tháº¯ng/thua/hÃ²a |
| `undo_move` | engine.py | board, r, c | XÃ³a quÃ¢n (dÃ¹ng cho undo request) |
| `get_ai_move` | ai.py | board, game_type, difficulty | Entry point - láº¥y nÆ°á»›c Ä‘i AI |
| `_get_tictactoe_move` | ai.py | board, difficulty | AI cho Tic-Tac-Toe |
| `_get_caro_move` | ai.py | board, difficulty | AI cho Caro |
| `_minimax_ttt` | ai.py | board, depth, is_max, alpha, beta | Minimax cho Tic-Tac-Toe |
| `_minimax_caro` | ai.py | board, depth, is_max, alpha, beta, last_move | Minimax cho Caro |
| `_evaluate_board` | ai.py | board | ÄÃ¡nh giÃ¡ Ä‘iá»ƒm board (heuristic) |
| `_get_neighbor_moves` | ai.py | board, radius | Láº¥y cÃ¡c Ã´ gáº§n quÃ¢n cá» (tá»‘i Æ°u search space) |
| `_find_immediate_caro_move` | ai.py | board, moves, player | TÃ¬m nÆ°á»›c tháº¯ng ngay láº­p tá»©c |
| `_find_vcf_move` | ai.py | board, moves, player | TÃ¬m nÆ°á»›c táº¡o Open-4 (Victory Continuous Flow) |

---

## ğŸ¤ Ná»™i Dung Thuyáº¿t TrÃ¬nh

### 1. Giá»›i Thiá»‡u Vai TrÃ² (1 phÃºt)
"Em phá»¥ trÃ¡ch pháº§n **Game Logic vÃ  AI System**, lÃ  bá»™ nÃ£o cá»§a game. Em Ä‘áº£m nhiá»‡m 2 modules chÃ­nh:
- **Game Engine** (engine.py): Kiá»ƒm tra nÆ°á»›c Ä‘i há»£p lá»‡, phÃ¡t hiá»‡n tháº¯ng/thua
- **AI System** (ai.py): Thuáº­t toÃ¡n Minimax Ä‘á»ƒ AI chÆ¡i game thÃ´ng minh"

### 2. Giáº£i ThÃ­ch Thuáº­t ToÃ¡n Minimax (3 phÃºt)

**Demo vá»›i diagram**:
```
        LÆ°á»£t AI (Max)
       /      |      \
      5       3       -1    â† AI chá»n 5
     / \     / \     / \
    5  2    3 -5   -1 0    LÆ°á»£t Human (Min)
```

**NÃ³i**:
"Minimax hoáº¡t Ä‘á»™ng nhÆ° sau: AI giáº£ Ä‘á»‹nh Ä‘á»‘i thá»§ cÅ©ng chÆ¡i tá»‘i Æ°u. á» lá»›p Max, AI chá»n Ä‘iá»ƒm cao nháº¥t. á» lá»›p Min, giáº£ Ä‘á»‹nh Ä‘á»‘i thá»§ sáº½ chá»n Ä‘iá»ƒm tháº¥p nháº¥t Ä‘á»ƒ AI thua.

VÃ­ dá»¥ vá»›i Tic-Tac-Toe:
- AI duyá»‡t táº¥t cáº£ nÆ°á»›c Ä‘i cÃ³ thá»ƒ
- Vá»›i má»—i nÆ°á»›c, giáº£ Ä‘á»‹nh Ä‘á»‘i thá»§ sáº½ chÆ¡i tá»‘i Æ°u nháº¥t
- Chá»n nÆ°á»›c Ä‘i dáº«n Ä‘áº¿n káº¿t quáº£ tá»‘t nháº¥t cho AI

NhÆ°ng váº¥n Ä‘á» lÃ  Ä‘á»™ phá»©c táº¡p O(b^d) quÃ¡ lá»›n vá»›i Caro. NÃªn em dÃ¹ng ká»¹ thuáº­t **Alpha-Beta Pruning**."

### 3. Alpha-Beta Pruning (2 phÃºt)

**Váº½ diagram**:
```
         Max (alpha=-inf, beta=+inf)
        /         \
   Min (a=3)       Min (pruned!)
    / \             / \
   3   5           2   ?
```

**NÃ³i**:
"Alpha-Beta Pruning cáº¯t bá» cÃ¡c nhÃ¡nh khÃ´ng cáº§n duyá»‡t:
- `alpha`: Äiá»ƒm tá»‘t nháº¥t mÃ  Max Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c
- `beta`: Äiá»ƒm tá»‘t nháº¥t mÃ  Min Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c
- Náº¿u `beta <= alpha`: khÃ´ng cáº§n duyá»‡t ná»¯a, cáº¯t bá» nhÃ¡nh

Trong thá»±c táº¿, ká»¹ thuáº­t nÃ y giáº£m tá»« O(b^d) xuá»‘ng O(b^(d/2), giÃºp AI Caro cháº¡y Ä‘Æ°á»£c vá»›i depth=2."

### 4. Luá»“ng Check Winner (1.5 phÃºt)

**Demo code + giáº£i thÃ­ch**:
```python
def check_winner(board, game_type, last_move):
    r, c = last_move['r'], last_move['c']
    player = board[r][c]
    win_len = 5  # Cho Caro
    
    # Kiá»ƒm tra 4 hÆ°á»›ng
    for dr, dc in [(0,1), (1,0), (1,1), (1,-1)]:
        line = [(r, c)]
        
        # Äáº¿m tiáº¿n + Ä‘áº¿m lÃ¹i
        # Náº¿u len(line) >= 5 â†’ tháº¯ng!
```

**NÃ³i**:
"HÃ m `check_winner` kiá»ƒm tra sau má»—i nÆ°á»›c Ä‘i:
1. Láº¥y vá»‹ trÃ­ nÆ°á»›c Ä‘i cuá»‘i
2. Duyá»‡t 4 hÆ°á»›ng: ngang, dá»c, 2 Ä‘Æ°á»ng chÃ©o
3. Vá»›i má»—i hÆ°á»›ng: Ä‘áº¿m tiáº¿n vÃ  Ä‘áº¿m lÃ¹i
4. Náº¿u Ä‘á»§ 5 (hoáº·c 3 vá»›i Tic-Tac-Toe) â†’ cÃ³ ngÆ°á»i tháº¯ng
5. Náº¿u board Ä‘áº§y mÃ  khÃ´ng ai tháº¯ng â†’ hÃ²a"

### 5. Äá»™ KhÃ³ AI (1 phÃºt)

"Em implement 3 má»©c Ä‘á»™ khÃ³:
- **Easy**: Random moves hoáº·c depth=1
- **Medium**: Minimax depth=3 (Tic-Tac-Toe) hoáº·c depth=1 (Caro)
- **Hard**: Full Minimax depth=5 (Tic-Tac-Toe) hoáº·c depth=2 (Caro)

Vá»›i Caro em cÃ²n thÃªm cÃ¡c check Ä‘áº·c biá»‡t:
- TÃ¬m nÆ°á»›c tháº¯ng ngay láº­p tá»©c
- Cháº·n Ä‘á»‘i thá»§ tháº¯ng ngay
- TÃ¬m nÆ°á»›c táº¡o Open-4 (tháº¯ng cháº¯c)"

### 6. Tá»•ng Káº¿t (0.5 phÃºt)

"Pháº§n Game Logic Ä‘áº£m báº£o game cháº¡y Ä‘Ãºng quy táº¯c, phÃ¡t hiá»‡n tháº¯ng thua chÃ­nh xÃ¡c. Pháº§n AI táº¡o Ä‘á»‘i thá»§ thÃ´ng minh cho ngÆ°á»i chÆ¡i luyá»‡n táº­p. ÄÃ¢y lÃ  ná»n táº£ng Ä‘á»ƒ game hoáº¡t Ä‘á»™ng."

---

## ğŸ’¡ Tips Há»c Hiá»‡u Quáº£

1. **Hiá»ƒu Minimax trÆ°á»›c khi Ä‘á»c code**
   - Xem video vá» Minimax trÃªn YouTube
   - Code tá»± tay 1 Minimax Ä‘Æ¡n giáº£n cho Tic-Tac-Toe

2. **Trace code báº±ng debugger**
   - Äáº·t breakpoint trong `_minimax_ttt`
   - Xem board thay Ä‘á»•i nhÆ° tháº¿ nÃ o qua má»—i recursive call

3. **Test vá»›i cÃ¡c case Ä‘Æ¡n giáº£n**
   - Board AI sáº¯p tháº¯ng â†’ xem AI cÃ³ chá»n Ä‘Ãºng khÃ´ng
   - Board Human sáº¯p tháº¯ng â†’ xem AI cÃ³ cháº·n khÃ´ng

4. **Váº½ diagram**
   - Váº½ cÃ¢y Minimax cho 1 board Ä‘Æ¡n giáº£n
   - TÃ­nh tay Ä‘iá»ƒm cá»§a má»—i nhÃ¡nh Ä‘á»ƒ hiá»ƒu logic

---

ChÃºc báº¡n há»c tá»‘t! Minimax lÃ  thuáº­t toÃ¡n cá»• Ä‘iá»ƒn nhÆ°ng cá»±c ká»³ hay! ğŸ®
